{"version":3,"sources":["../src/chatgpt-api.ts","../src/types.ts","../src/chatgpt-conversation.ts","../src/fetch.ts","../src/fetch-sse.ts","../src/stream-async-iterable.ts","../src/utils.ts","../src/openai-auth.ts"],"sourcesContent":["import ExpiryMap from 'expiry-map'\nimport pTimeout from 'p-timeout'\nimport { v4 as uuidv4 } from 'uuid'\n\nimport * as types from './types'\nimport { ChatGPTConversation } from './chatgpt-conversation'\nimport { fetch } from './fetch'\nimport { fetchSSE } from './fetch-sse'\nimport { markdownToText } from './utils'\n\nconst KEY_ACCESS_TOKEN = 'accessToken'\nconst USER_AGENT =\n  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n\nexport class ChatGPTAPI {\n  protected _sessionToken: string\n  protected _clearanceToken: string\n  protected _markdown: boolean\n  protected _debug: boolean\n  protected _apiBaseUrl: string\n  protected _backendApiBaseUrl: string\n  protected _userAgent: string\n  protected _headers: Record<string, string>\n  protected _user: types.User | null = null\n\n  // Stores access tokens for `accessTokenTTL` milliseconds before needing to refresh\n  protected _accessTokenCache: ExpiryMap<string, string>\n\n  /**\n   * Creates a new client wrapper around the unofficial ChatGPT REST API.\n   *\n   * Note that your IP address and `userAgent` must match the same values that you used\n   * to obtain your `clearanceToken`.\n   *\n   * @param opts.sessionToken = **Required** OpenAI session token which can be found in a valid session's cookies (see readme for instructions)\n   * @param opts.clearanceToken = **Required** Cloudflare `cf_clearance` cookie value (see readme for instructions)\n   * @param apiBaseUrl - Optional override; the base URL for ChatGPT webapp's API (`/api`)\n   * @param backendApiBaseUrl - Optional override; the base URL for the ChatGPT backend API (`/backend-api`)\n   * @param userAgent - Optional override; the `user-agent` header to use with ChatGPT requests\n   * @param accessTokenTTL - Optional override; how long in milliseconds access tokens should last before being forcefully refreshed\n   * @param accessToken - Optional default access token if you already have a valid one generated\n   * @param heaaders - Optional additional HTTP headers to be added to each `fetch` request\n   * @param debug - Optional enables logging debugging into to stdout\n   */\n  constructor(opts: {\n    sessionToken: string\n\n    clearanceToken: string\n\n    /** @defaultValue `true` **/\n    markdown?: boolean\n\n    /** @defaultValue `'https://chat.openai.com/api'` **/\n    apiBaseUrl?: string\n\n    /** @defaultValue `'https://chat.openai.com/backend-api'` **/\n    backendApiBaseUrl?: string\n\n    /** @defaultValue `Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'` **/\n    userAgent?: string\n\n    /** @defaultValue 1 hour **/\n    accessTokenTTL?: number\n\n    /** @defaultValue `undefined` **/\n    accessToken?: string\n\n    /** @defaultValue `undefined` **/\n    headers?: Record<string, string>\n\n    /** @defaultValue `false` **/\n    debug?: boolean\n  }) {\n    const {\n      sessionToken,\n      clearanceToken,\n      markdown = true,\n      apiBaseUrl = 'https://chat.openai.com/api',\n      backendApiBaseUrl = 'https://chat.openai.com/backend-api',\n      userAgent = USER_AGENT,\n      accessTokenTTL = 60 * 60000, // 1 hour\n      accessToken,\n      headers,\n      debug = false\n    } = opts\n\n    this._sessionToken = sessionToken\n    this._clearanceToken = clearanceToken\n    this._markdown = !!markdown\n    this._debug = !!debug\n    this._apiBaseUrl = apiBaseUrl\n    this._backendApiBaseUrl = backendApiBaseUrl\n    this._userAgent = userAgent\n    this._headers = {\n      'user-agent': this._userAgent,\n      'x-openai-assistant-app-id': '',\n      'accept-language': 'en-US,en;q=0.9',\n      origin: 'https://chat.openai.com',\n      referer: 'https://chat.openai.com/chat',\n      'sec-ch-ua':\n        '\"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\", \"Google Chrome\";v=\"108\"',\n      'sec-ch-ua-platform': '\"macOS\"',\n      'sec-fetch-dest': 'empty',\n      'sec-fetch-mode': 'cors',\n      'sec-fetch-site': 'same-origin',\n      ...headers\n    }\n\n    this._accessTokenCache = new ExpiryMap<string, string>(accessTokenTTL)\n    if (accessToken) {\n      this._accessTokenCache.set(KEY_ACCESS_TOKEN, accessToken)\n    }\n\n    if (!this._sessionToken) {\n      throw new types.ChatGPTError('ChatGPT invalid session token')\n    }\n\n    if (!this._clearanceToken) {\n      throw new types.ChatGPTError('ChatGPT invalid clearance token')\n    }\n  }\n\n  /**\n   * Gets the currently signed-in user, if authenticated, `null` otherwise.\n   */\n  get user() {\n    return this._user\n  }\n\n  /** Gets the current session token. */\n  get sessionToken() {\n    return this._sessionToken\n  }\n\n  /** Gets the current Cloudflare clearance token (`cf_clearance` cookie value). */\n  get clearanceToken() {\n    return this._clearanceToken\n  }\n\n  /** Gets the current user agent. */\n  get userAgent() {\n    return this._userAgent\n  }\n\n  /**\n   * Sends a message to ChatGPT, waits for the response to resolve, and returns\n   * the response.\n   *\n   * If you want to receive a stream of partial responses, use `opts.onProgress`.\n   * If you want to receive the full response, including message and conversation IDs,\n   * you can use `opts.onConversationResponse` or use the `ChatGPTAPI.getConversation`\n   * helper.\n   *\n   * @param message - The prompt message to send\n   * @param opts.conversationId - Optional ID of a conversation to continue\n   * @param opts.parentMessageId - Optional ID of the previous message in the conversation\n   * @param opts.messageId - Optional ID of the message to send (defaults to a random UUID)\n   * @param opts.action - Optional ChatGPT `action` (either `next` or `variant`)\n   * @param opts.timeoutMs - Optional timeout in milliseconds (defaults to no timeout)\n   * @param opts.onProgress - Optional callback which will be invoked every time the partial response is updated\n   * @param opts.onConversationResponse - Optional callback which will be invoked every time the partial response is updated with the full conversation response\n   * @param opts.abortSignal - Optional callback used to abort the underlying `fetch` call using an [AbortController](https://developer.mozilla.org/en-US/docs/Web/API/AbortController)\n   *\n   * @returns The response from ChatGPT\n   */\n  async sendMessage(\n    message: string,\n    opts: types.SendMessageOptions = {}\n  ): Promise<string> {\n    const {\n      conversationId,\n      parentMessageId = uuidv4(),\n      messageId = uuidv4(),\n      action = 'next',\n      timeoutMs,\n      onProgress,\n      onConversationResponse\n    } = opts\n\n    let { abortSignal } = opts\n\n    let abortController: AbortController = null\n    if (timeoutMs && !abortSignal) {\n      abortController = new AbortController()\n      abortSignal = abortController.signal\n    }\n\n    const accessToken = await this.refreshAccessToken()\n\n    const body: types.ConversationJSONBody = {\n      action,\n      messages: [\n        {\n          id: messageId,\n          role: 'user',\n          content: {\n            content_type: 'text',\n            parts: [message]\n          }\n        }\n      ],\n      model: 'text-davinci-002-render',\n      parent_message_id: parentMessageId\n    }\n\n    if (conversationId) {\n      body.conversation_id = conversationId\n    }\n\n    let response = ''\n\n    const responseP = new Promise<string>((resolve, reject) => {\n      const url = `${this._backendApiBaseUrl}/conversation`\n      const headers = {\n        ...this._headers,\n        Authorization: `Bearer ${accessToken}`,\n        Accept: 'text/event-stream',\n        'Content-Type': 'application/json',\n        Cookie: `cf_clearance=${this._clearanceToken}`\n      }\n\n      if (this._debug) {\n        console.log('POST', url, { body, headers })\n      }\n\n      fetchSSE(url, {\n        method: 'POST',\n        headers,\n        body: JSON.stringify(body),\n        signal: abortSignal,\n        onMessage: (data: string) => {\n          if (data === '[DONE]') {\n            return resolve(response)\n          }\n\n          try {\n            const parsedData: types.ConversationResponseEvent = JSON.parse(data)\n            if (onConversationResponse) {\n              onConversationResponse(parsedData)\n            }\n\n            const message = parsedData.message\n            // console.log('event', JSON.stringify(parsedData, null, 2))\n\n            if (message) {\n              let text = message?.content?.parts?.[0]\n\n              if (text) {\n                if (!this._markdown) {\n                  text = markdownToText(text)\n                }\n\n                response = text\n\n                if (onProgress) {\n                  onProgress(text)\n                }\n              }\n            }\n          } catch (err) {\n            console.warn('fetchSSE onMessage unexpected error', err)\n            reject(err)\n          }\n        }\n      }).catch((err) => {\n        const errMessageL = err.toString().toLowerCase()\n\n        if (\n          response &&\n          (errMessageL === 'error: typeerror: terminated' ||\n            errMessageL === 'typeerror: terminated')\n        ) {\n          // OpenAI sometimes forcefully terminates the socket from their end before\n          // the HTTP request has resolved cleanly. In my testing, these cases tend to\n          // happen when OpenAI has already send the last `response`, so we can ignore\n          // the `fetch` error in this case.\n          return resolve(response)\n        } else {\n          return reject(err)\n        }\n      })\n    })\n\n    if (timeoutMs) {\n      if (abortController) {\n        // This will be called when a timeout occurs in order for us to forcibly\n        // ensure that the underlying HTTP request is aborted.\n        ;(responseP as any).cancel = () => {\n          abortController.abort()\n        }\n      }\n\n      return pTimeout(responseP, {\n        milliseconds: timeoutMs,\n        message: 'ChatGPT timed out waiting for response'\n      })\n    } else {\n      return responseP\n    }\n  }\n\n  /**\n   * @returns `true` if the client has a valid acces token or `false` if refreshing\n   * the token fails.\n   */\n  async getIsAuthenticated() {\n    try {\n      void (await this.refreshAccessToken())\n      return true\n    } catch (err) {\n      return false\n    }\n  }\n\n  /**\n   * Refreshes the client's access token which will succeed only if the session\n   * is still valid.\n   */\n  async ensureAuth() {\n    return await this.refreshAccessToken()\n  }\n\n  /**\n   * Attempts to refresh the current access token using the ChatGPT\n   * `sessionToken` cookie.\n   *\n   * Access tokens will be cached for up to `accessTokenTTL` milliseconds to\n   * prevent refreshing access tokens too frequently.\n   *\n   * @returns A valid access token\n   * @throws An error if refreshing the access token fails.\n   */\n  async refreshAccessToken(): Promise<string> {\n    const cachedAccessToken = this._accessTokenCache.get(KEY_ACCESS_TOKEN)\n    if (cachedAccessToken) {\n      return cachedAccessToken\n    }\n\n    let response: Response\n    try {\n      const url = `${this._apiBaseUrl}/auth/session`\n      const headers = {\n        ...this._headers,\n        cookie: `cf_clearance=${this._clearanceToken}; __Secure-next-auth.session-token=${this._sessionToken}`,\n        accept: '*/*'\n      }\n\n      if (this._debug) {\n        console.log('GET', url, headers)\n      }\n\n      const res = await fetch(url, {\n        headers\n      }).then((r) => {\n        response = r\n\n        if (!r.ok) {\n          const error = new types.ChatGPTError(`${r.status} ${r.statusText}`)\n          error.response = r\n          error.statusCode = r.status\n          error.statusText = r.statusText\n          throw error\n        }\n\n        return r.json() as any as types.SessionResult\n      })\n\n      const accessToken = res?.accessToken\n\n      if (!accessToken) {\n        const error = new types.ChatGPTError('Unauthorized')\n        error.response = response\n        error.statusCode = response?.status\n        error.statusText = response?.statusText\n        throw error\n      }\n\n      const appError = res?.error\n      if (appError) {\n        if (appError === 'RefreshAccessTokenError') {\n          const error = new types.ChatGPTError('session token may have expired')\n          error.response = response\n          error.statusCode = response?.status\n          error.statusText = response?.statusText\n          throw error\n        } else {\n          const error = new types.ChatGPTError(appError)\n          error.response = response\n          error.statusCode = response?.status\n          error.statusText = response?.statusText\n          throw error\n        }\n      }\n\n      if (res.user) {\n        this._user = res.user\n      }\n\n      this._accessTokenCache.set(KEY_ACCESS_TOKEN, accessToken)\n      return accessToken\n    } catch (err: any) {\n      if (this._debug) {\n        console.error(err)\n      }\n\n      const error = new types.ChatGPTError(\n        `ChatGPT failed to refresh auth token. ${err.toString()}`\n      )\n      error.response = response\n      error.statusCode = response?.status\n      error.statusText = response?.statusText\n      error.originalError = err\n      throw error\n    }\n  }\n\n  /**\n   * Gets a new ChatGPTConversation instance, which can be used to send multiple\n   * messages as part of a single conversation.\n   *\n   * @param opts.conversationId - Optional ID of the previous message in a conversation\n   * @param opts.parentMessageId - Optional ID of the previous message in a conversation\n   * @returns The new conversation instance\n   */\n  getConversation(\n    opts: { conversationId?: string; parentMessageId?: string } = {}\n  ) {\n    return new ChatGPTConversation(this, opts)\n  }\n}\n","export type ContentType = 'text'\n\nexport type Role = 'user' | 'assistant'\n\n/**\n * https://chat.openapi.com/api/auth/session\n */\nexport type SessionResult = {\n  /**\n   * Authenticated user\n   */\n  user: User\n\n  /**\n   * ISO date of the expiration date of the access token\n   */\n  expires: string\n\n  /**\n   * The access token\n   */\n  accessToken: string\n\n  /**\n   * If there was an error associated with this request\n   */\n  error?: string | null\n}\n\nexport type User = {\n  /**\n   * ID of the user\n   */\n  id: string\n\n  /**\n   * Name of the user\n   */\n  name: string\n\n  /**\n   * Email of the user\n   */\n  email?: string\n\n  /**\n   * Image of the user\n   */\n  image: string\n\n  /**\n   * Picture of the user\n   */\n  picture: string\n\n  /**\n   * Groups the user is in\n   */\n  groups: string[]\n\n  /**\n   * Features the user is in\n   */\n  features: string[]\n}\n\n/**\n * https://chat.openapi.com/backend-api/models\n */\nexport type ModelsResult = {\n  /**\n   * Array of models\n   */\n  models: Model[]\n}\n\nexport type Model = {\n  /**\n   * Name of the model\n   */\n  slug: string\n\n  /**\n   * Max tokens of the model\n   */\n  max_tokens: number\n\n  /**\n   * Whether or not the model is special\n   */\n  is_special: boolean\n}\n\n/**\n * https://chat.openapi.com/backend-api/moderations\n */\nexport type ModerationsJSONBody = {\n  /**\n   * Input for the moderation decision\n   */\n  input: string\n\n  /**\n   * The model to use in the decision\n   */\n  model: AvailableModerationModels\n}\n\nexport type AvailableModerationModels = 'text-moderation-playground'\n\n/**\n * https://chat.openapi.com/backend-api/moderations\n */\nexport type ModerationsJSONResult = {\n  /**\n   * Whether or not the input is flagged\n   */\n  flagged: boolean\n\n  /**\n   * Whether or not the input is blocked\n   */\n  blocked: boolean\n\n  /**\n   * The ID of the decision\n   */\n  moderation_id: string\n}\n\n/**\n * https://chat.openapi.com/backend-api/conversation\n */\nexport type ConversationJSONBody = {\n  /**\n   * The action to take\n   */\n  action: string\n\n  /**\n   * The ID of the conversation\n   */\n  conversation_id?: string\n\n  /**\n   * Prompts to provide\n   */\n  messages: Prompt[]\n\n  /**\n   * The model to use\n   */\n  model: string\n\n  /**\n   * The parent message ID\n   */\n  parent_message_id: string\n}\n\nexport type Prompt = {\n  /**\n   * The content of the prompt\n   */\n  content: PromptContent\n\n  /**\n   * The ID of the prompt\n   */\n  id: string\n\n  /**\n   * The role played in the prompt\n   */\n  role: Role\n}\n\nexport type PromptContent = {\n  /**\n   * The content type of the prompt\n   */\n  content_type: ContentType\n\n  /**\n   * The parts to the prompt\n   */\n  parts: string[]\n}\n\n/**\n * https://chat.openapi.com/backend-api/conversation/message_feedback\n */\nexport type MessageFeedbackJSONBody = {\n  /**\n   * The ID of the conversation\n   */\n  conversation_id: string\n\n  /**\n   * The message ID\n   */\n  message_id: string\n\n  /**\n   * The rating\n   */\n  rating: MessageFeedbackRating\n\n  /**\n   * Tags to give the rating\n   */\n  tags?: MessageFeedbackTags[]\n\n  /**\n   * The text to include\n   */\n  text?: string\n}\n\nexport type MessageFeedbackTags = 'harmful' | 'false' | 'not-helpful'\n\nexport type MessageFeedbackResult = {\n  /**\n   * The message ID\n   */\n  message_id: string\n\n  /**\n   * The ID of the conversation\n   */\n  conversation_id: string\n\n  /**\n   * The ID of the user\n   */\n  user_id: string\n\n  /**\n   * The rating\n   */\n  rating: MessageFeedbackRating\n\n  /**\n   * The text the server received, including tags\n   */\n  text?: string\n}\n\nexport type MessageFeedbackRating = 'thumbsUp' | 'thumbsDown'\n\nexport type ConversationResponseEvent = {\n  message?: Message\n  conversation_id?: string\n  error?: string | null\n}\n\nexport type Message = {\n  id: string\n  content: MessageContent\n  role: string\n  user: string | null\n  create_time: string | null\n  update_time: string | null\n  end_turn: null\n  weight: number\n  recipient: string\n  metadata: MessageMetadata\n}\n\nexport type MessageContent = {\n  content_type: string\n  parts: string[]\n}\n\nexport type MessageMetadata = any\nexport type MessageActionType = 'next' | 'variant'\n\nexport type SendMessageOptions = {\n  conversationId?: string\n  parentMessageId?: string\n  messageId?: string\n  action?: MessageActionType\n  timeoutMs?: number\n  onProgress?: (partialResponse: string) => void\n  onConversationResponse?: (response: ConversationResponseEvent) => void\n  abortSignal?: AbortSignal\n}\n\nexport type SendConversationMessageOptions = Omit<\n  SendMessageOptions,\n  'conversationId' | 'parentMessageId'\n>\n\nexport class ChatGPTError extends Error {\n  statusCode?: number\n  statusText?: string\n  response?: Response\n  originalError?: Error\n}\n","import * as types from './types'\nimport { type ChatGPTAPI } from './chatgpt-api'\n\n/**\n * A conversation wrapper around the ChatGPTAPI. This allows you to send\n * multiple messages to ChatGPT and receive responses, without having to\n * manually pass the conversation ID and parent message ID for each message.\n */\nexport class ChatGPTConversation {\n  api: ChatGPTAPI\n  conversationId: string = undefined\n  parentMessageId: string = undefined\n\n  /**\n   * Creates a new conversation wrapper around the ChatGPT API.\n   *\n   * @param api - The ChatGPT API instance to use\n   * @param opts.conversationId - Optional ID of a conversation to continue\n   * @param opts.parentMessageId - Optional ID of the previous message in the conversation\n   */\n  constructor(\n    api: ChatGPTAPI,\n    opts: { conversationId?: string; parentMessageId?: string } = {}\n  ) {\n    this.api = api\n    this.conversationId = opts.conversationId\n    this.parentMessageId = opts.parentMessageId\n  }\n\n  /**\n   * Sends a message to ChatGPT, waits for the response to resolve, and returns\n   * the response.\n   *\n   * If this is the first message in the conversation, the conversation ID and\n   * parent message ID will be automatically set.\n   *\n   * This allows you to send multiple messages to ChatGPT and receive responses,\n   * without having to manually pass the conversation ID and parent message ID\n   * for each message.\n   *\n   * @param message - The prompt message to send\n   * @param opts.onProgress - Optional callback which will be invoked every time the partial response is updated\n   * @param opts.onConversationResponse - Optional callback which will be invoked every time the partial response is updated with the full conversation response\n   * @param opts.abortSignal - Optional callback used to abort the underlying `fetch` call using an [AbortController](https://developer.mozilla.org/en-US/docs/Web/API/AbortController)\n   *\n   * @returns The response from ChatGPT\n   */\n  async sendMessage(\n    message: string,\n    opts: types.SendConversationMessageOptions = {}\n  ): Promise<string> {\n    const { onConversationResponse, ...rest } = opts\n\n    return this.api.sendMessage(message, {\n      ...rest,\n      conversationId: this.conversationId,\n      parentMessageId: this.parentMessageId,\n      onConversationResponse: (response) => {\n        if (response.conversation_id) {\n          this.conversationId = response.conversation_id\n        }\n\n        if (response.message?.id) {\n          this.parentMessageId = response.message.id\n        }\n\n        if (onConversationResponse) {\n          return onConversationResponse(response)\n        }\n      }\n    })\n  }\n}\n","/// <reference lib=\"dom\" />\n\n// Use `fetch` for node.js >= 18\n// Use `fetch` for all other environments, including browsers\nconst fetch = globalThis.fetch\n\nif (typeof fetch !== 'function') {\n  throw new Error(\n    'Invalid environment: global fetch not defined; `chatgpt` requires Node.js >= 18 at the moment due to Cloudflare protections'\n  )\n}\n\nexport { fetch }\n","import { createParser } from 'eventsource-parser'\n\nimport * as types from './types'\nimport { fetch } from './fetch'\nimport { streamAsyncIterable } from './stream-async-iterable'\n\nexport async function fetchSSE(\n  url: string,\n  options: Parameters<typeof fetch>[1] & { onMessage: (data: string) => void }\n) {\n  const { onMessage, ...fetchOptions } = options\n  const res = await fetch(url, fetchOptions)\n  if (!res.ok) {\n    const msg = `ChatGPTAPI error ${res.status || res.statusText}`\n    const error = new types.ChatGPTError(msg)\n    error.statusCode = res.status\n    error.statusText = res.statusText\n    error.response = res\n    throw error\n  }\n\n  const parser = createParser((event) => {\n    if (event.type === 'event') {\n      onMessage(event.data)\n    }\n  })\n\n  if (!res.body.getReader) {\n    // Vercel polyfills `fetch` with `node-fetch`, which doesn't conform to\n    // web standards, so this is a workaround...\n    const body: NodeJS.ReadableStream = res.body as any\n\n    if (!body.on || !body.read) {\n      throw new types.ChatGPTError('unsupported \"fetch\" implementation')\n    }\n\n    body.on('readable', () => {\n      let chunk: string | Buffer\n      while (null !== (chunk = body.read())) {\n        parser.feed(chunk.toString())\n      }\n    })\n  } else {\n    for await (const chunk of streamAsyncIterable(res.body)) {\n      const str = new TextDecoder().decode(chunk)\n      parser.feed(str)\n    }\n  }\n}\n","export async function* streamAsyncIterable<T>(stream: ReadableStream<T>) {\n  const reader = stream.getReader()\n  try {\n    while (true) {\n      const { done, value } = await reader.read()\n      if (done) {\n        return\n      }\n      yield value\n    }\n  } finally {\n    reader.releaseLock()\n  }\n}\n","import { remark } from 'remark'\nimport stripMarkdown from 'strip-markdown'\n\nexport function markdownToText(markdown?: string): string {\n  return remark()\n    .use(stripMarkdown)\n    .processSync(markdown ?? '')\n    .toString()\n}\n","import * as fs from 'node:fs'\nimport * as os from 'node:os'\n\nimport delay from 'delay'\nimport {\n  type Browser,\n  type ElementHandle,\n  type Page,\n  type Protocol,\n  type PuppeteerLaunchOptions\n} from 'puppeteer'\nimport puppeteer from 'puppeteer-extra'\nimport StealthPlugin from 'puppeteer-extra-plugin-stealth'\n\nimport * as types from './types'\n\npuppeteer.use(StealthPlugin())\n\n/**\n * Represents everything that's required to pass into `ChatGPTAPI` in order\n * to authenticate with the unofficial ChatGPT API.\n */\nexport type OpenAIAuth = {\n  userAgent: string\n  clearanceToken: string\n  sessionToken: string\n  cookies?: Record<string, Protocol.Network.Cookie>\n}\n\n/**\n * Bypasses OpenAI's use of Cloudflare to get the cookies required to use\n * ChatGPT. Uses Puppeteer with a stealth plugin under the hood.\n *\n * If you pass `email` and `password`, then it will log into the account and\n * include a `sessionToken` in the response.\n *\n * If you don't pass `email` and `password`, then it will just return a valid\n * `clearanceToken`.\n *\n * This can be useful because `clearanceToken` expires after ~2 hours, whereas\n * `sessionToken` generally lasts much longer. We recommend renewing your\n * `clearanceToken` every hour or so and creating a new instance of `ChatGPTAPI`\n * with your updated credentials.\n */\nexport async function getOpenAIAuth({\n  email,\n  password,\n  browser,\n  timeoutMs = 2 * 60 * 1000,\n  isGoogleLogin = false\n}: {\n  email?: string\n  password?: string\n  browser?: Browser\n  timeoutMs?: number\n  isGoogleLogin?: boolean\n}): Promise<OpenAIAuth> {\n  let page: Page\n  let origBrowser = browser\n\n  try {\n    if (!browser) {\n      browser = await getBrowser()\n    }\n\n    const userAgent = await browser.userAgent()\n    page = (await browser.pages())[0] || (await browser.newPage())\n    page.setDefaultTimeout(timeoutMs)\n\n    await page.goto('https://chat.openai.com/auth/login')\n\n    await checkForChatGPTAtCapacity(page)\n\n    // NOTE: this is where you may encounter a CAPTCHA\n\n    await page.waitForSelector('#__next .btn-primary', { timeout: timeoutMs })\n\n    // once we get to this point, the Cloudflare cookies are available\n    await delay(1000)\n\n    // login as well (optional)\n    if (email && password) {\n      await Promise.all([\n        page.click('#__next .btn-primary'),\n        page.waitForNavigation({\n          waitUntil: 'networkidle0'\n        })\n      ])\n\n      let submitP: Promise<void>\n\n      if (isGoogleLogin) {\n        await page.click('button[data-provider=\"google\"]')\n        await page.waitForSelector('input[type=\"email\"]')\n        await page.type('input[type=\"email\"]', email, { delay: 10 })\n        await Promise.all([\n          page.waitForNavigation(),\n          await page.keyboard.press('Enter')\n        ])\n        await page.waitForSelector('input[type=\"password\"]', { visible: true })\n        await page.type('input[type=\"password\"]', password, { delay: 10 })\n        submitP = page.keyboard.press('Enter')\n      } else {\n        await page.waitForSelector('#username')\n        await page.type('#username', email, { delay: 10 })\n        await page.click('button[type=\"submit\"]')\n        await page.waitForSelector('#password')\n        await page.type('#password', password, { delay: 10 })\n        submitP = page.click('button[type=\"submit\"]')\n      }\n\n      await Promise.all([\n        submitP,\n\n        new Promise<void>((resolve, reject) => {\n          let resolved = false\n\n          async function waitForCapacityText() {\n            if (resolved) {\n              return\n            }\n\n            try {\n              await checkForChatGPTAtCapacity(page)\n\n              if (!resolved) {\n                setTimeout(waitForCapacityText, 500)\n              }\n            } catch (err) {\n              if (!resolved) {\n                resolved = true\n                return reject(err)\n              }\n            }\n          }\n\n          page\n            .waitForNavigation({\n              waitUntil: 'networkidle0'\n            })\n            .then(() => {\n              if (!resolved) {\n                resolved = true\n                resolve()\n              }\n            })\n            .catch((err) => {\n              if (!resolved) {\n                resolved = true\n                reject(err)\n              }\n            })\n\n          setTimeout(waitForCapacityText, 500)\n        })\n      ])\n    }\n\n    const pageCookies = await page.cookies()\n    const cookies = pageCookies.reduce(\n      (map, cookie) => ({ ...map, [cookie.name]: cookie }),\n      {}\n    )\n\n    const authInfo: OpenAIAuth = {\n      userAgent,\n      clearanceToken: cookies['cf_clearance']?.value,\n      sessionToken: cookies['__Secure-next-auth.session-token']?.value,\n      cookies\n    }\n\n    return authInfo\n  } catch (err) {\n    console.error(err)\n    throw err\n  } finally {\n    if (origBrowser) {\n      if (page) {\n        await page.close()\n      }\n    } else if (browser) {\n      await browser.close()\n    }\n\n    page = null\n    browser = null\n  }\n}\n\n/**\n * Launches a non-puppeteer instance of Chrome. Note that in my testing, I wasn't\n * able to use the built-in `puppeteer` version of Chromium because Cloudflare\n * recognizes it and blocks access.\n */\nexport async function getBrowser(launchOptions?: PuppeteerLaunchOptions) {\n  return puppeteer.launch({\n    headless: false,\n    args: ['--no-sandbox', '--exclude-switches', 'enable-automation'],\n    ignoreHTTPSErrors: true,\n    executablePath: defaultChromeExecutablePath(),\n    ...launchOptions\n  })\n}\n\n/**\n * Gets the default path to chrome's executable for the current platform.\n */\nexport const defaultChromeExecutablePath = (): string => {\n  switch (os.platform()) {\n    case 'win32':\n      return 'C:\\\\ProgramFiles\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe'\n\n    case 'darwin':\n      return '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n\n    default:\n      /**\n       * Since two (2) separate chrome releases exists on linux\n       * we first do a check to ensure we're executing the right one.\n       */\n      const chromeExists = fs.existsSync('/usr/bin/google-chrome')\n\n      return chromeExists\n        ? '/usr/bin/google-chrome'\n        : '/usr/bin/google-chrome-stable'\n  }\n}\n\nasync function checkForChatGPTAtCapacity(page: Page) {\n  let res: ElementHandle<Node>[]\n\n  try {\n    res = await page.$x(\"//div[contains(., 'ChatGPT is at capacity')]\")\n    console.log('capacity text', res)\n  } catch (err) {\n    // ignore errors likely due to navigation\n    console.warn(err.toString())\n  }\n\n  if (res?.length) {\n    const error = new types.ChatGPTError('ChatGPT is at capacity')\n    error.statusCode = 503\n    throw error\n  }\n}\n"],"mappings":";AAAA,OAAO,eAAe;AACtB,OAAO,cAAc;AACrB,SAAS,MAAM,cAAc;;;ACmStB,IAAM,eAAN,cAA2B,MAAM;AAKxC;;;AClSO,IAAM,sBAAN,MAA0B;AAAA,EAY/B,YACE,KACA,OAA8D,CAAC,GAC/D;AAbF,0BAAyB;AACzB,2BAA0B;AAaxB,SAAK,MAAM;AACX,SAAK,iBAAiB,KAAK;AAC3B,SAAK,kBAAkB,KAAK;AAAA,EAC9B;AAAA,EAoBA,MAAM,YACJ,SACA,OAA6C,CAAC,GAC7B;AACjB,UAAM,EAAE,2BAA2B,KAAK,IAAI;AAE5C,WAAO,KAAK,IAAI,YAAY,SAAS;AAAA,MACnC,GAAG;AAAA,MACH,gBAAgB,KAAK;AAAA,MACrB,iBAAiB,KAAK;AAAA,MACtB,wBAAwB,CAAC,aAAa;AAzD5C;AA0DQ,YAAI,SAAS,iBAAiB;AAC5B,eAAK,iBAAiB,SAAS;AAAA,QACjC;AAEA,aAAI,cAAS,YAAT,mBAAkB,IAAI;AACxB,eAAK,kBAAkB,SAAS,QAAQ;AAAA,QAC1C;AAEA,YAAI,wBAAwB;AAC1B,iBAAO,uBAAuB,QAAQ;AAAA,QACxC;AAAA,MACF;AAAA,IACF,CAAC;AAAA,EACH;AACF;;;ACpEA,IAAM,QAAQ,WAAW;AAEzB,IAAI,OAAO,UAAU,YAAY;AAC/B,QAAM,IAAI;AAAA,IACR;AAAA,EACF;AACF;;;ACVA,SAAS,oBAAoB;;;ACA7B,gBAAuB,oBAAuB,QAA2B;AACvE,QAAM,SAAS,OAAO,UAAU;AAChC,MAAI;AACF,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,MAAM;AACR;AAAA,MACF;AACA,YAAM;AAAA,IACR;AAAA,EACF,UAAE;AACA,WAAO,YAAY;AAAA,EACrB;AACF;;;ADPA,eAAsB,SACpB,KACA,SACA;AACA,QAAM,EAAE,cAAc,aAAa,IAAI;AACvC,QAAM,MAAM,MAAM,MAAM,KAAK,YAAY;AACzC,MAAI,CAAC,IAAI,IAAI;AACX,UAAM,MAAM,oBAAoB,IAAI,UAAU,IAAI;AAClD,UAAM,QAAQ,IAAU,aAAa,GAAG;AACxC,UAAM,aAAa,IAAI;AACvB,UAAM,aAAa,IAAI;AACvB,UAAM,WAAW;AACjB,UAAM;AAAA,EACR;AAEA,QAAM,SAAS,aAAa,CAAC,UAAU;AACrC,QAAI,MAAM,SAAS,SAAS;AAC1B,gBAAU,MAAM,IAAI;AAAA,IACtB;AAAA,EACF,CAAC;AAED,MAAI,CAAC,IAAI,KAAK,WAAW;AAGvB,UAAM,OAA8B,IAAI;AAExC,QAAI,CAAC,KAAK,MAAM,CAAC,KAAK,MAAM;AAC1B,YAAM,IAAU,aAAa,oCAAoC;AAAA,IACnE;AAEA,SAAK,GAAG,YAAY,MAAM;AACxB,UAAI;AACJ,aAAO,UAAU,QAAQ,KAAK,KAAK,IAAI;AACrC,eAAO,KAAK,MAAM,SAAS,CAAC;AAAA,MAC9B;AAAA,IACF,CAAC;AAAA,EACH,OAAO;AACL,qBAAiB,SAAS,oBAAoB,IAAI,IAAI,GAAG;AACvD,YAAM,MAAM,IAAI,YAAY,EAAE,OAAO,KAAK;AAC1C,aAAO,KAAK,GAAG;AAAA,IACjB;AAAA,EACF;AACF;;;AEhDA,SAAS,cAAc;AACvB,OAAO,mBAAmB;AAEnB,SAAS,eAAe,UAA2B;AACxD,SAAO,OAAO,EACX,IAAI,aAAa,EACjB,YAAY,YAAY,EAAE,EAC1B,SAAS;AACd;;;ANEA,IAAM,mBAAmB;AACzB,IAAM,aACJ;AAEK,IAAM,aAAN,MAAiB;AAAA,EA8BtB,YAAY,MA4BT;AAjDH,SAAU,QAA2B;AAkDnC,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA,WAAW;AAAA,MACX,aAAa;AAAA,MACb,oBAAoB;AAAA,MACpB,YAAY;AAAA,MACZ,iBAAiB,KAAK;AAAA,MACtB;AAAA,MACA;AAAA,MACA,QAAQ;AAAA,IACV,IAAI;AAEJ,SAAK,gBAAgB;AACrB,SAAK,kBAAkB;AACvB,SAAK,YAAY,CAAC,CAAC;AACnB,SAAK,SAAS,CAAC,CAAC;AAChB,SAAK,cAAc;AACnB,SAAK,qBAAqB;AAC1B,SAAK,aAAa;AAClB,SAAK,WAAW;AAAA,MACd,cAAc,KAAK;AAAA,MACnB,6BAA6B;AAAA,MAC7B,mBAAmB;AAAA,MACnB,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,aACE;AAAA,MACF,sBAAsB;AAAA,MACtB,kBAAkB;AAAA,MAClB,kBAAkB;AAAA,MAClB,kBAAkB;AAAA,MAClB,GAAG;AAAA,IACL;AAEA,SAAK,oBAAoB,IAAI,UAA0B,cAAc;AACrE,QAAI,aAAa;AACf,WAAK,kBAAkB,IAAI,kBAAkB,WAAW;AAAA,IAC1D;AAEA,QAAI,CAAC,KAAK,eAAe;AACvB,YAAM,IAAU,aAAa,+BAA+B;AAAA,IAC9D;AAEA,QAAI,CAAC,KAAK,iBAAiB;AACzB,YAAM,IAAU,aAAa,iCAAiC;AAAA,IAChE;AAAA,EACF;AAAA,EAKA,IAAI,OAAO;AACT,WAAO,KAAK;AAAA,EACd;AAAA,EAGA,IAAI,eAAe;AACjB,WAAO,KAAK;AAAA,EACd;AAAA,EAGA,IAAI,iBAAiB;AACnB,WAAO,KAAK;AAAA,EACd;AAAA,EAGA,IAAI,YAAY;AACd,WAAO,KAAK;AAAA,EACd;AAAA,EAuBA,MAAM,YACJ,SACA,OAAiC,CAAC,GACjB;AACjB,UAAM;AAAA,MACJ;AAAA,MACA,kBAAkB,OAAO;AAAA,MACzB,YAAY,OAAO;AAAA,MACnB,SAAS;AAAA,MACT;AAAA,MACA;AAAA,MACA;AAAA,IACF,IAAI;AAEJ,QAAI,EAAE,YAAY,IAAI;AAEtB,QAAI,kBAAmC;AACvC,QAAI,aAAa,CAAC,aAAa;AAC7B,wBAAkB,IAAI,gBAAgB;AACtC,oBAAc,gBAAgB;AAAA,IAChC;AAEA,UAAM,cAAc,MAAM,KAAK,mBAAmB;AAElD,UAAM,OAAmC;AAAA,MACvC;AAAA,MACA,UAAU;AAAA,QACR;AAAA,UACE,IAAI;AAAA,UACJ,MAAM;AAAA,UACN,SAAS;AAAA,YACP,cAAc;AAAA,YACd,OAAO,CAAC,OAAO;AAAA,UACjB;AAAA,QACF;AAAA,MACF;AAAA,MACA,OAAO;AAAA,MACP,mBAAmB;AAAA,IACrB;AAEA,QAAI,gBAAgB;AAClB,WAAK,kBAAkB;AAAA,IACzB;AAEA,QAAI,WAAW;AAEf,UAAM,YAAY,IAAI,QAAgB,CAAC,SAAS,WAAW;AACzD,YAAM,MAAM,GAAG,KAAK;AACpB,YAAM,UAAU;AAAA,QACd,GAAG,KAAK;AAAA,QACR,eAAe,UAAU;AAAA,QACzB,QAAQ;AAAA,QACR,gBAAgB;AAAA,QAChB,QAAQ,gBAAgB,KAAK;AAAA,MAC/B;AAEA,UAAI,KAAK,QAAQ;AACf,gBAAQ,IAAI,QAAQ,KAAK,EAAE,MAAM,QAAQ,CAAC;AAAA,MAC5C;AAEA,eAAS,KAAK;AAAA,QACZ,QAAQ;AAAA,QACR;AAAA,QACA,MAAM,KAAK,UAAU,IAAI;AAAA,QACzB,QAAQ;AAAA,QACR,WAAW,CAAC,SAAiB;AAtOrC;AAuOU,cAAI,SAAS,UAAU;AACrB,mBAAO,QAAQ,QAAQ;AAAA,UACzB;AAEA,cAAI;AACF,kBAAM,aAA8C,KAAK,MAAM,IAAI;AACnE,gBAAI,wBAAwB;AAC1B,qCAAuB,UAAU;AAAA,YACnC;AAEA,kBAAMA,WAAU,WAAW;AAG3B,gBAAIA,UAAS;AACX,kBAAI,QAAO,WAAAA,YAAA,gBAAAA,SAAS,YAAT,mBAAkB,UAAlB,mBAA0B;AAErC,kBAAI,MAAM;AACR,oBAAI,CAAC,KAAK,WAAW;AACnB,yBAAO,eAAe,IAAI;AAAA,gBAC5B;AAEA,2BAAW;AAEX,oBAAI,YAAY;AACd,6BAAW,IAAI;AAAA,gBACjB;AAAA,cACF;AAAA,YACF;AAAA,UACF,SAAS,KAAP;AACA,oBAAQ,KAAK,uCAAuC,GAAG;AACvD,mBAAO,GAAG;AAAA,UACZ;AAAA,QACF;AAAA,MACF,CAAC,EAAE,MAAM,CAAC,QAAQ;AAChB,cAAM,cAAc,IAAI,SAAS,EAAE,YAAY;AAE/C,YACE,aACC,gBAAgB,kCACf,gBAAgB,0BAClB;AAKA,iBAAO,QAAQ,QAAQ;AAAA,QACzB,OAAO;AACL,iBAAO,OAAO,GAAG;AAAA,QACnB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,QAAI,WAAW;AACb,UAAI,iBAAiB;AAGnB;AAAC,QAAC,UAAkB,SAAS,MAAM;AACjC,0BAAgB,MAAM;AAAA,QACxB;AAAA,MACF;AAEA,aAAO,SAAS,WAAW;AAAA,QACzB,cAAc;AAAA,QACd,SAAS;AAAA,MACX,CAAC;AAAA,IACH,OAAO;AACL,aAAO;AAAA,IACT;AAAA,EACF;AAAA,EAMA,MAAM,qBAAqB;AACzB,QAAI;AACF,WAAM,MAAM,KAAK,mBAAmB;AACpC,aAAO;AAAA,IACT,SAAS,KAAP;AACA,aAAO;AAAA,IACT;AAAA,EACF;AAAA,EAMA,MAAM,aAAa;AACjB,WAAO,MAAM,KAAK,mBAAmB;AAAA,EACvC;AAAA,EAYA,MAAM,qBAAsC;AAC1C,UAAM,oBAAoB,KAAK,kBAAkB,IAAI,gBAAgB;AACrE,QAAI,mBAAmB;AACrB,aAAO;AAAA,IACT;AAEA,QAAI;AACJ,QAAI;AACF,YAAM,MAAM,GAAG,KAAK;AACpB,YAAM,UAAU;AAAA,QACd,GAAG,KAAK;AAAA,QACR,QAAQ,gBAAgB,KAAK,qDAAqD,KAAK;AAAA,QACvF,QAAQ;AAAA,MACV;AAEA,UAAI,KAAK,QAAQ;AACf,gBAAQ,IAAI,OAAO,KAAK,OAAO;AAAA,MACjC;AAEA,YAAM,MAAM,MAAM,MAAM,KAAK;AAAA,QAC3B;AAAA,MACF,CAAC,EAAE,KAAK,CAAC,MAAM;AACb,mBAAW;AAEX,YAAI,CAAC,EAAE,IAAI;AACT,gBAAM,QAAQ,IAAU,aAAa,GAAG,EAAE,UAAU,EAAE,YAAY;AAClE,gBAAM,WAAW;AACjB,gBAAM,aAAa,EAAE;AACrB,gBAAM,aAAa,EAAE;AACrB,gBAAM;AAAA,QACR;AAEA,eAAO,EAAE,KAAK;AAAA,MAChB,CAAC;AAED,YAAM,cAAc,2BAAK;AAEzB,UAAI,CAAC,aAAa;AAChB,cAAM,QAAQ,IAAU,aAAa,cAAc;AACnD,cAAM,WAAW;AACjB,cAAM,aAAa,qCAAU;AAC7B,cAAM,aAAa,qCAAU;AAC7B,cAAM;AAAA,MACR;AAEA,YAAM,WAAW,2BAAK;AACtB,UAAI,UAAU;AACZ,YAAI,aAAa,2BAA2B;AAC1C,gBAAM,QAAQ,IAAU,aAAa,gCAAgC;AACrE,gBAAM,WAAW;AACjB,gBAAM,aAAa,qCAAU;AAC7B,gBAAM,aAAa,qCAAU;AAC7B,gBAAM;AAAA,QACR,OAAO;AACL,gBAAM,QAAQ,IAAU,aAAa,QAAQ;AAC7C,gBAAM,WAAW;AACjB,gBAAM,aAAa,qCAAU;AAC7B,gBAAM,aAAa,qCAAU;AAC7B,gBAAM;AAAA,QACR;AAAA,MACF;AAEA,UAAI,IAAI,MAAM;AACZ,aAAK,QAAQ,IAAI;AAAA,MACnB;AAEA,WAAK,kBAAkB,IAAI,kBAAkB,WAAW;AACxD,aAAO;AAAA,IACT,SAAS,KAAP;AACA,UAAI,KAAK,QAAQ;AACf,gBAAQ,MAAM,GAAG;AAAA,MACnB;AAEA,YAAM,QAAQ,IAAU;AAAA,QACtB,yCAAyC,IAAI,SAAS;AAAA,MACxD;AACA,YAAM,WAAW;AACjB,YAAM,aAAa,qCAAU;AAC7B,YAAM,aAAa,qCAAU;AAC7B,YAAM,gBAAgB;AACtB,YAAM;AAAA,IACR;AAAA,EACF;AAAA,EAUA,gBACE,OAA8D,CAAC,GAC/D;AACA,WAAO,IAAI,oBAAoB,MAAM,IAAI;AAAA,EAC3C;AACF;;;AO7aA,YAAY,QAAQ;AACpB,YAAY,QAAQ;AAEpB,OAAO,WAAW;AAQlB,OAAO,eAAe;AACtB,OAAO,mBAAmB;AAI1B,UAAU,IAAI,cAAc,CAAC;AA4B7B,eAAsB,cAAc;AAAA,EAClC;AAAA,EACA;AAAA,EACA;AAAA,EACA,YAAY,IAAI,KAAK;AAAA,EACrB,gBAAgB;AAClB,GAMwB;AAxDxB;AAyDE,MAAI;AACJ,MAAI,cAAc;AAElB,MAAI;AACF,QAAI,CAAC,SAAS;AACZ,gBAAU,MAAM,WAAW;AAAA,IAC7B;AAEA,UAAM,YAAY,MAAM,QAAQ,UAAU;AAC1C,YAAQ,MAAM,QAAQ,MAAM,GAAG,MAAO,MAAM,QAAQ,QAAQ;AAC5D,SAAK,kBAAkB,SAAS;AAEhC,UAAM,KAAK,KAAK,oCAAoC;AAEpD,UAAM,0BAA0B,IAAI;AAIpC,UAAM,KAAK,gBAAgB,wBAAwB,EAAE,SAAS,UAAU,CAAC;AAGzE,UAAM,MAAM,GAAI;AAGhB,QAAI,SAAS,UAAU;AACrB,YAAM,QAAQ,IAAI;AAAA,QAChB,KAAK,MAAM,sBAAsB;AAAA,QACjC,KAAK,kBAAkB;AAAA,UACrB,WAAW;AAAA,QACb,CAAC;AAAA,MACH,CAAC;AAED,UAAI;AAEJ,UAAI,eAAe;AACjB,cAAM,KAAK,MAAM,gCAAgC;AACjD,cAAM,KAAK,gBAAgB,qBAAqB;AAChD,cAAM,KAAK,KAAK,uBAAuB,OAAO,EAAE,OAAO,GAAG,CAAC;AAC3D,cAAM,QAAQ,IAAI;AAAA,UAChB,KAAK,kBAAkB;AAAA,UACvB,MAAM,KAAK,SAAS,MAAM,OAAO;AAAA,QACnC,CAAC;AACD,cAAM,KAAK,gBAAgB,0BAA0B,EAAE,SAAS,KAAK,CAAC;AACtE,cAAM,KAAK,KAAK,0BAA0B,UAAU,EAAE,OAAO,GAAG,CAAC;AACjE,kBAAU,KAAK,SAAS,MAAM,OAAO;AAAA,MACvC,OAAO;AACL,cAAM,KAAK,gBAAgB,WAAW;AACtC,cAAM,KAAK,KAAK,aAAa,OAAO,EAAE,OAAO,GAAG,CAAC;AACjD,cAAM,KAAK,MAAM,uBAAuB;AACxC,cAAM,KAAK,gBAAgB,WAAW;AACtC,cAAM,KAAK,KAAK,aAAa,UAAU,EAAE,OAAO,GAAG,CAAC;AACpD,kBAAU,KAAK,MAAM,uBAAuB;AAAA,MAC9C;AAEA,YAAM,QAAQ,IAAI;AAAA,QAChB;AAAA,QAEA,IAAI,QAAc,CAAC,SAAS,WAAW;AACrC,cAAI,WAAW;AAEf,yBAAe,sBAAsB;AACnC,gBAAI,UAAU;AACZ;AAAA,YACF;AAEA,gBAAI;AACF,oBAAM,0BAA0B,IAAI;AAEpC,kBAAI,CAAC,UAAU;AACb,2BAAW,qBAAqB,GAAG;AAAA,cACrC;AAAA,YACF,SAAS,KAAP;AACA,kBAAI,CAAC,UAAU;AACb,2BAAW;AACX,uBAAO,OAAO,GAAG;AAAA,cACnB;AAAA,YACF;AAAA,UACF;AAEA,eACG,kBAAkB;AAAA,YACjB,WAAW;AAAA,UACb,CAAC,EACA,KAAK,MAAM;AACV,gBAAI,CAAC,UAAU;AACb,yBAAW;AACX,sBAAQ;AAAA,YACV;AAAA,UACF,CAAC,EACA,MAAM,CAAC,QAAQ;AACd,gBAAI,CAAC,UAAU;AACb,yBAAW;AACX,qBAAO,GAAG;AAAA,YACZ;AAAA,UACF,CAAC;AAEH,qBAAW,qBAAqB,GAAG;AAAA,QACrC,CAAC;AAAA,MACH,CAAC;AAAA,IACH;AAEA,UAAM,cAAc,MAAM,KAAK,QAAQ;AACvC,UAAM,UAAU,YAAY;AAAA,MAC1B,CAAC,KAAK,YAAY,EAAE,GAAG,KAAK,CAAC,OAAO,OAAO,OAAO;AAAA,MAClD,CAAC;AAAA,IACH;AAEA,UAAM,WAAuB;AAAA,MAC3B;AAAA,MACA,iBAAgB,aAAQ,oBAAR,mBAAyB;AAAA,MACzC,eAAc,aAAQ,wCAAR,mBAA6C;AAAA,MAC3D;AAAA,IACF;AAEA,WAAO;AAAA,EACT,SAAS,KAAP;AACA,YAAQ,MAAM,GAAG;AACjB,UAAM;AAAA,EACR,UAAE;AACA,QAAI,aAAa;AACf,UAAI,MAAM;AACR,cAAM,KAAK,MAAM;AAAA,MACnB;AAAA,IACF,WAAW,SAAS;AAClB,YAAM,QAAQ,MAAM;AAAA,IACtB;AAEA,WAAO;AACP,cAAU;AAAA,EACZ;AACF;AAOA,eAAsB,WAAW,eAAwC;AACvE,SAAO,UAAU,OAAO;AAAA,IACtB,UAAU;AAAA,IACV,MAAM,CAAC,gBAAgB,sBAAsB,mBAAmB;AAAA,IAChE,mBAAmB;AAAA,IACnB,gBAAgB,4BAA4B;AAAA,IAC5C,GAAG;AAAA,EACL,CAAC;AACH;AAKO,IAAM,8BAA8B,MAAc;AACvD,UAAW,YAAS,GAAG;AAAA,IACrB,KAAK;AACH,aAAO;AAAA,IAET,KAAK;AACH,aAAO;AAAA,IAET;AAKE,YAAM,eAAkB,cAAW,wBAAwB;AAE3D,aAAO,eACH,2BACA;AAAA,EACR;AACF;AAEA,eAAe,0BAA0B,MAAY;AACnD,MAAI;AAEJ,MAAI;AACF,UAAM,MAAM,KAAK,GAAG,8CAA8C;AAClE,YAAQ,IAAI,iBAAiB,GAAG;AAAA,EAClC,SAAS,KAAP;AAEA,YAAQ,KAAK,IAAI,SAAS,CAAC;AAAA,EAC7B;AAEA,MAAI,2BAAK,QAAQ;AACf,UAAM,QAAQ,IAAU,aAAa,wBAAwB;AAC7D,UAAM,aAAa;AACnB,UAAM;AAAA,EACR;AACF;","names":["message"]}